{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "291ec3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82acf939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([49.])\n",
      "tensor([174.7500])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1.5],requires_grad = True)\n",
    "b = torch.tensor([2.5],requires_grad = True)\n",
    "\n",
    "\n",
    "\n",
    "x = 2*a + 3*b\n",
    "y = 5*a*a + 3*b*b*b\n",
    "z = 2*x + 3*y\n",
    "\n",
    "z.backward()\n",
    "\n",
    "print(a.grad)\n",
    "print(b.grad)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "884b4fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical gradient:\n",
      "dz/da: 49.0\n",
      "dz/db: 174.75\n"
     ]
    }
   ],
   "source": [
    "def manual_gradient_computation(a, b):\n",
    "    x = 2 * a + 3 * b\n",
    "    y = 5 * a * a + 3 * b * b * b\n",
    "    z = 2 * x + 3 * y\n",
    "\n",
    "    dz_dx = 2\n",
    "    dz_dy = 3\n",
    "    dx_da = 2\n",
    "    dx_db = 3\n",
    "    dy_da = 10 * a\n",
    "    dy_db = 9 * b * b\n",
    "    dz_da = dz_dx * dx_da + dz_dy * dy_da\n",
    "    dz_db = dz_dx * dx_db + dz_dy * dy_db\n",
    "    return dz_da, dz_db\n",
    "\n",
    "a_val = 1.5\n",
    "b_val = 2.5\n",
    "grad_a, grad_b = manual_gradient_computation(a_val, b_val)\n",
    "print(\"Analytical gradient:\")\n",
    "print(\"dz/da:\", grad_a)\n",
    "print(\"dz/db:\", grad_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99e5616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch gradient:\n",
      "da/dx: tensor([2.5000])\n",
      "da/dw: tensor([1.5000])\n",
      "da/db: tensor([1.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#q2\n",
    "\n",
    "x = torch.tensor([1.5], requires_grad=True)\n",
    "w = torch.tensor([2.5], requires_grad=True)\n",
    "b = torch.tensor([3.5], requires_grad=True)\n",
    "\n",
    "u = w*x\n",
    "v=u+b\n",
    "a=torch.nn.functional.relu(v)\n",
    "\n",
    "a.backward()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Pytorch gradient:\")\n",
    "print(\"da/dx:\",x.grad)\n",
    "print(\"da/dw:\",w.grad)\n",
    "print(\"da/db:\",b.grad)\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed3f4364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical gradient:\n",
      "da/dx: 2.5\n",
      "da/dw: 1.5\n",
      "da/db: 1\n"
     ]
    }
   ],
   "source": [
    "def manual_relu_gradient(x, w, b):\n",
    "    u = w * x\n",
    "    v = u + b\n",
    "\n",
    "    # ReLU activation condition\n",
    "    if v > 0:\n",
    "        da_dv = 1\n",
    "    else:\n",
    "        da_dv = 0\n",
    "\n",
    "    dv_du = 1\n",
    "    dv_db = 1\n",
    "    du_dx = w\n",
    "    du_dw = x\n",
    "\n",
    "    da_dx = da_dv * dv_du * du_dx\n",
    "    da_dw = da_dv * dv_du * du_dw\n",
    "    da_db = da_dv * dv_db\n",
    "    return da_dx, da_dw, da_db\n",
    "\n",
    "x_val = 1.5\n",
    "w_val = 2.5\n",
    "b_val = 3.5\n",
    "\n",
    "grad_x, grad_w, grad_b = manual_relu_gradient(x_val, w_val, b_val)\n",
    "print(\"Analytical gradient:\")\n",
    "print(\"da/dx:\", grad_x)\n",
    "print(\"da/dw:\", grad_w)\n",
    "print(\"da/db:\", grad_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "273d669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch gradient:\n",
      "da/dx: tensor([0.0018])\n",
      "da/dw: tensor([0.0011])\n",
      "da/db: tensor([0.0007])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#q3\n",
    "\n",
    "x = torch.tensor([1.5], requires_grad=True)\n",
    "w = torch.tensor([2.5], requires_grad=True)\n",
    "b = torch.tensor([3.5], requires_grad=True)\n",
    "\n",
    "u = w*x\n",
    "v=u+b\n",
    "a=torch.nn.functional.sigmoid(v)\n",
    "\n",
    "a.backward()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Pytorch gradient:\")\n",
    "print(\"da/dx:\",x.grad)\n",
    "print(\"da/dw:\",w.grad)\n",
    "print(\"da/db:\",b.grad)\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9750c58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical gradient:\n",
      "da/dx: 0.001772916917562916\n",
      "da/dw: 0.0010637501505377498\n",
      "da/db: 0.0007091667670251665\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def manual_sigmoid_gradient(x, w, b):\n",
    "    u = w * x\n",
    "    v = u + b\n",
    "\n",
    "    a = 1 / (1 + np.exp(-v))\n",
    "\n",
    "    da_dv = a * (1 - a)\n",
    "    dv_du = 1\n",
    "    dv_db = 1\n",
    "    du_dx = w\n",
    "    du_dw = x\n",
    "\n",
    "    da_dx = da_dv * dv_du * du_dx\n",
    "    da_dw = da_dv * dv_du * du_dw\n",
    "    da_db = da_dv * dv_db\n",
    "\n",
    "    return da_dx, da_dw, da_db\n",
    "\n",
    "x_val = 1.5\n",
    "w_val = 2.5\n",
    "b_val = 3.5\n",
    "grad_x, grad_w, grad_b = manual_sigmoid_gradient(x_val, w_val, b_val)\n",
    "print(\"Analytical gradient:\")\n",
    "print(\"da/dx:\", grad_x)\n",
    "print(\"da/dw:\", grad_w)\n",
    "print(\"da/db:\", grad_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b2244ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch gradient:\n",
      "dy/dx: tensor([-0.0098])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#q4\n",
    "\n",
    "x = torch.tensor([1.5], requires_grad=True)\n",
    "y = torch.exp(-(x*x)-(2*x)-torch.sin(x))\n",
    "\n",
    "y.backward()\n",
    "print(\"Pytorch gradient:\")\n",
    "print(\"dy/dx:\", x.grad)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd049666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical gradient:\n",
      "dy/dx: -0.009813377482506094\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def manual_gradient_computation(x):\n",
    "    a = x * x\n",
    "    b = 2 * x\n",
    "    c = np.sin(x)\n",
    "    y = np.exp(-(a + b + c))\n",
    "\n",
    "    da_dx = 2 * x\n",
    "    db_dx = 2\n",
    "    dc_dx = np.cos(x)\n",
    "    dy_dx = y * (-(da_dx + db_dx + dc_dx))\n",
    "\n",
    "    return dy_dx\n",
    "\n",
    "\n",
    "x_val = 1.5\n",
    "grad_x = manual_gradient_computation(x_val)\n",
    "print(\"Analytical gradient:\")\n",
    "print(\"dy/dx:\", grad_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d286680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch gradient:\n",
      "dy/dx: tensor([326.])\n"
     ]
    }
   ],
   "source": [
    "#q5\n",
    "x = torch.tensor([2.0], requires_grad = True)\n",
    "\n",
    "y = 8*x*x*x*x + 3*x*x*x + 7*x*x + 6*x +3\n",
    "\n",
    "y.backward()\n",
    "print(\"Pytorch gradient:\")\n",
    "print(\"dy/dx:\", x.grad)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "092d6e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical gradient:\n",
      "dy/dx: 326.0\n"
     ]
    }
   ],
   "source": [
    "def manual_gradient_computation(x):\n",
    "    dy_dx = 32*x**3 + 9*x**2 + 14*x + 6\n",
    "    return dy_dx\n",
    "\n",
    "\n",
    "x_val = 2.0\n",
    "grad_x = manual_gradient_computation(x_val)\n",
    "print(\"Analytical gradient:\")\n",
    "print(\"dy/dx:\", grad_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7b00b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch gradient:\n",
      "df/dx: tensor([0.0073])\n",
      "df/dw: tensor([0.0146])\n",
      "df/db: tensor([0.0031])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#q6\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "x = torch.tensor([1.5], requires_grad=True)\n",
    "y = torch.tensor([2.5], requires_grad=True)\n",
    "z = torch.tensor([3.5], requires_grad=True)\n",
    "\n",
    "w = torch.tanh(torch.log(1+z*((2*x)/torch.sin(y))))\n",
    "\n",
    "w.backward()\n",
    "print(\"Pytorch gradient:\")\n",
    "print(\"df/dx:\", x.grad)\n",
    "print(\"df/dw:\", y.grad)\n",
    "print(\"df/db:\", z.grad)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "728d2c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical gradient:\n",
      "dw/dx: tensor([0.0073], grad_fn=<MulBackward0>)\n",
      "dw/dy: tensor([0.0146], grad_fn=<MulBackward0>)\n",
      "dw/dz: tensor([0.0031], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def manual_gradient_computation(x, y, z):\n",
    "    a = 2 * x\n",
    "    b = torch.sin(y)\n",
    "    c = a / b\n",
    "    d = z * c\n",
    "    e = torch.log(1 + d)\n",
    "    f = torch.tanh(e)\n",
    "\n",
    "    da_dx = 2\n",
    "    db_dy = torch.cos(y)\n",
    "    dc_da = 1 / b\n",
    "    dc_db = -a / b**2\n",
    "    dd_dc = z\n",
    "    dd_dz = c\n",
    "    de_dd = 1 / (1 + d)\n",
    "    df_de = 1 - torch.tanh(e)**2\n",
    "\n",
    "    df_dx = df_de * de_dd * dd_dc * dc_da * da_dx\n",
    "    df_dy = df_de * de_dd * dd_dc * dc_db * db_dy\n",
    "    df_dz = df_de * de_dd * dd_dz\n",
    "\n",
    "    return df_dx,df_dy,df_dz\n",
    "\n",
    "grad_x, grad_y, grad_z = manual_gradient_computation(x, y, z)\n",
    "print(\"Analytical gradient:\")\n",
    "print(\"dw/dx:\", grad_x)\n",
    "print(\"dw/dy:\", grad_y)\n",
    "print(\"dw/dz:\", grad_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a282e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python dl_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
